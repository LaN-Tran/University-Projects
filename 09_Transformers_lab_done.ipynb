{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "380.8px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "09_Transformers_lab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "44a7c6ce82be997c5ea9b294b89289a2",
          "grade": false,
          "grade_id": "cell-bf12d2c95f08882e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "U77kYAyPVpr0"
      },
      "source": [
        "# Introduction to Python and Natural Language Technologies\n",
        "\n",
        "__Laboratory 09, Transformers__\n",
        "\n",
        "__April 14, 2020__\n",
        "\n",
        "The starter code in this notebook is the same as in Assignment 8. The number of training epochs is increased.\n",
        "\n",
        "Your task is to replace the model with a Transformer.\n",
        "\n",
        "Transformer is known to perform worse than LSTMs on small datasets so do not be alarmed when you see a drop in performance.\n",
        "\n",
        "If you successfully solved Assignment 8, you may start by replacing the starter code with your implementation.\n",
        "\n",
        "Passing level: Task 1, 2\n",
        "\n",
        "Extra level: Task 3, 4\n",
        "\n",
        "## Task 1 - Replace LSTMClassifier with a Transformer-based encoder without positional encoding and attention masking.\n",
        "\n",
        "We suggest reading this [tutorial](https://pytorch.org/tutorials/beginner/transformer_tutorial.html) first.\n",
        "The tutorial is for a sequence-to-sequence model which can be easily adapted to sequence classification.\n",
        "You can use the first output of the Transformer as the representation of the full word.\n",
        "\n",
        "Make sure that the Transformer parameters are not hardwired.\n",
        "\n",
        "Don't forget to rename the class since it's no longer an 'LSTM' classifier.\n",
        "\n",
        "Try out a few options for the Transformer parameters and summarize your findings in a few sentences in the following cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8c47eb3776c42d76884cbc0fe0475c0e",
          "grade": true,
          "grade_id": "cell-a7aa12d0e3a76681",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "VllenPw6Vpr8"
      },
      "source": [
        "##CODE: TASK 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyWIcvXAZ_cU"
      },
      "source": [
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, output_size, dropout=0.5):\n",
        "      super(TransformerModel, self).__init__()\n",
        "      from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "        \n",
        "      encoder_layers = TransformerEncoderLayer(d_model=ninp, nhead=nhead, dim_feedforward=nhid, dropout =dropout)\n",
        "      self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "\n",
        "      self.encoder = nn.Embedding(ntoken, ninp)\n",
        "      self.ninp = ninp\n",
        "\n",
        "      self.decoder = nn.Linear(ninp, output_size)\n",
        "      \n",
        "\n",
        "      self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "\n",
        "      src = self.encoder(src)\n",
        "      print(f'src.shape ={src.shape}')\n",
        "      output = self.transformer_encoder(src)\n",
        "      output = self.decoder(output)\n",
        "      final_output= F.log_softmax(output, dim=-1) \n",
        "      return final_output[:,0,:]"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_QFEGq_dczT"
      },
      "source": [
        "'''\n",
        "input_size = len(vocab)\n",
        "embedding_size = 30\n",
        "hidden_size = 64\n",
        "output_size = train_df.label.nunique()\n",
        "\n",
        "model = LSTMClassifier(input_size, embedding_size, hidden_size, output_size)\n",
        "model\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by78-kbsat95"
      },
      "source": [
        "ntokens = len(vocab) # the size of vocabulary\n",
        "nip = 60 # embedding dimension = nip = embed_size = d_model\n",
        "nhid = 64 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2 # the number of heads in the multiheadattention models\n",
        "dropout = 0.2 # the dropout value\n",
        "output_size= train_df.label.nunique()\n",
        "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers,output_size, dropout)"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbr4_Yg2mgmo"
      },
      "source": [
        "**TESTING THE MODEL FOR TUNING:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWNyWoJJfFGX",
        "outputId": "9d6033a1-79fc-481e-ec87-daa62a24f67f"
      },
      "source": [
        "m = nn.LogSoftmax()\n",
        "#output = m(input)\n",
        "\n",
        "# check the dimension output: For tuning (changing) the sequence-to-sequence task to normal classification of the sequence task\n",
        "# batch_size = 128\n",
        "c=1\n",
        "for X_batch, seqlen_batch, y_batch in train_iter.iterate_once():\n",
        "        if c==1:\n",
        "          y_out = model(X_batch)\n",
        "\n",
        "          #t= y_out.view(-1, ntokens)\n",
        "          #print(t)\n",
        "          #print(t.shape)\n",
        "          #print(y_out)\n",
        "          print(y_out.shape)\n",
        "          print(type(y_out))\n",
        "          #print(m(y_out))\n",
        "          #print(y_out[0][0])\n",
        "        else:\n",
        "          break\n",
        "# output shape [batch_size, sequence_len, vocab size] => 1 token in the sequence is a vector of length 40 (= ntoken= vocab size)"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src.shape =torch.Size([128, 48, 60])\n",
            "torch.Size([128, 48, 3])\n",
            "<class 'torch.Tensor'>\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "torch.Size([128, 48, 3])\n",
            "<class 'torch.Tensor'>\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "torch.Size([128, 48, 3])\n",
            "<class 'torch.Tensor'>\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "torch.Size([128, 48, 3])\n",
            "<class 'torch.Tensor'>\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "torch.Size([128, 48, 3])\n",
            "<class 'torch.Tensor'>\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "torch.Size([128, 48, 3])\n",
            "<class 'torch.Tensor'>\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "torch.Size([128, 48, 3])\n",
            "<class 'torch.Tensor'>\n",
            "src.shape =torch.Size([104, 48, 60])\n",
            "torch.Size([104, 48, 3])\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1a77c929cbebbe847e403f4a5c9e6da4",
          "grade": false,
          "grade_id": "cell-004d4bf68ee613e9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "JoRJJaOFVpr8"
      },
      "source": [
        "## Task 2 - Positional encoding\n",
        "\n",
        "Add positional encoding to the Transformer. \n",
        "You can take inspiration from Lecture 9.\n",
        "\n",
        "Make the base of the positional encoding (10000) by default configurable.\n",
        "\n",
        "Try out a few options and summarize your findings in the following cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1ca440ac010e8a9378bd40328202461d",
          "grade": true,
          "grade_id": "cell-096d202c82100b14",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "QwAm0i6eVpr9"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e75dee555dd574da05eb1929a0d51356",
          "grade": false,
          "grade_id": "cell-f252d069012d47aa",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "lnVC2d01Vpr9"
      },
      "source": [
        "## Task 3 - Attention masking\n",
        "\n",
        "The Transformer does not need to put any attention weight on PAD symbols.\n",
        "This can be done by supplying a mask to `TransformerEncoder`.\n",
        "\n",
        "Add this mask and summarize your findings in the following cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1bd097d7a55ee1101fff8d792137af4e",
          "grade": true,
          "grade_id": "cell-42ae5669a1e8cfa9",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "NzekoNdUVpr-"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "58797d8955403baa8095fa427e49c328",
          "grade": false,
          "grade_id": "cell-258a4fc7ddf91b6b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "UFIRn-tDVpr-"
      },
      "source": [
        "## Task 4 - Training improvement\n",
        "\n",
        "Transformers are notoriously hard to train.\n",
        "\n",
        "Try to improve the training process.\n",
        "Here is an incomplete list of tricks that may improve the training process:\n",
        "- learning rate decay\n",
        "- different initialization\n",
        "- warm up.\n",
        "\n",
        "You are encouraged to find further tricks.\n",
        "\n",
        "Try at least two tricks and summarize your findings. It does not matter if they do not improve the accuracy of the classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1c9c1a297b94aaed6216b7a8506a0244",
          "grade": true,
          "grade_id": "cell-0bf3db089cd6027a",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "7GZcDl1UVpr_"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvCw34A8VpsA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v665qUxyVpsB"
      },
      "source": [
        "# Cloning the data repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpiASUzpVpsB",
        "outputId": "133ef801-e546-472f-9eba-1cb62101cf48"
      },
      "source": [
        "language = \"hun\"\n",
        "unimorph_path = f\"data/unimorph_{language}/\"\n",
        "pipe = subprocess.Popen(f\"git clone https://github.com/unimorph/hun.git {unimorph_path}\",\n",
        "                        shell=True, stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n",
        "stdout, stderr = pipe.communicate()\n",
        "print(stdout.decode('utf8'))\n",
        "print(stderr.decode('utf8'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Cloning into 'data/unimorph_hun'...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJfrLLvTVpsB"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUNThrflVpsC"
      },
      "source": [
        "data = pd.read_table(f\"{unimorph_path}/{language}\", names=['lemma', 'infl', 'tags'], skip_blank_lines=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT6YOKIHVpsC"
      },
      "source": [
        "# Target extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhH6a68WVpsC"
      },
      "source": [
        "def extract_target(tags_str):\n",
        "    \"\"\"Extracts target if present, returns None otherwise.\"\"\"\n",
        "    tags = tags_str.split(\";\")\n",
        "    if tags[0] != 'V':\n",
        "        return None\n",
        "    if len(tags) < 6:\n",
        "        return None\n",
        "    return tags[1]\n",
        " \n",
        "data['target'] = data.tags.apply(extract_target)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMSuWQ6JVpsD"
      },
      "source": [
        "data = data[data.target.notnull()]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZZx0ZlWVpsD",
        "outputId": "ed6506eb-cd17-4d6a-9e69-276329c376f2"
      },
      "source": [
        "data['target'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IND     42784\n",
              "COND    21036\n",
              "SBJV    20986\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lFnpqzwVpsD"
      },
      "source": [
        "# Train/dev/test set creation\n",
        "\n",
        "We avoid lemma overlaps between the splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0oQGPcKVpsE",
        "outputId": "1ba799eb-1a46-4b72-fae2-d50e130c3230"
      },
      "source": [
        "lemmas = data.lemma.unique()\n",
        "len(lemmas), type(lemmas)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2109, numpy.ndarray)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TutOYUtTVpsE"
      },
      "source": [
        "np.random.seed(12)\n",
        "np.random.shuffle(lemmas)\n",
        "train_size = int(0.8 * len(lemmas))\n",
        "dev_size = int(0.1 * len(lemmas))\n",
        "train_lemmas = lemmas[:train_size]\n",
        "dev_lemmas = lemmas[train_size:train_size+dev_size]\n",
        "test_lemmas = lemmas[train_size+dev_size:]\n",
        "\n",
        "train_lemmas = set(train_lemmas)\n",
        "dev_lemmas = set(dev_lemmas)\n",
        "test_lemmas = set(test_lemmas)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVxp-CDHVpsE",
        "outputId": "7c0021f2-a764-4a8e-941f-a033b81a883b"
      },
      "source": [
        "train_df = data[data.lemma.isin(train_lemmas)]\n",
        "dev_df = data[data.lemma.isin(dev_lemmas)]\n",
        "test_df = data[data.lemma.isin(test_lemmas)]\n",
        "len(train_df), len(dev_df), len(test_df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67665, 8447, 8694)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeddHG3dVpsF"
      },
      "source": [
        "train_df = train_df.sample(1000, random_state=1).reset_index(drop=True)\n",
        "dev_df = dev_df.sample(200, random_state=1).reset_index(drop=True)\n",
        "test_df = test_df.sample(200, random_state=1).reset_index(drop=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZBTzYkpVpsF"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3Fbv0vNVpsF",
        "outputId": "8a75173a-2cae-42ad-8a00-c06f8eed44b0"
      },
      "source": [
        "alphabet = set()\n",
        "for token in train_df.infl:\n",
        "    alphabet |= set(token)\n",
        "len(alphabet)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjwM_Q69VpsF"
      },
      "source": [
        "alphabet.add('<PAD>')\n",
        "alphabet.add('<BOS>')\n",
        "alphabet.add('<EOS>')\n",
        "alphabet.add('<UNK>')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMeWCH5YVpsG",
        "outputId": "b259a0f1-fd96-4808-fd87-5517aab3ccba"
      },
      "source": [
        "vocab = {symbol: i for i, symbol in enumerate(alphabet)}\n",
        "len(vocab)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2YtVpXNVpsG",
        "outputId": "1aa003e4-1d4d-4003-c13e-061d7066b02a"
      },
      "source": [
        "def encode_token(token):\n",
        "    ids = []\n",
        "    ids.append(vocab['<BOS>'])\n",
        "    # dev and test might contain characters outside the alphabet\n",
        "    ids.extend(vocab.get(c, vocab['<UNK>']) for c in token)\n",
        "    ids.append(vocab['<EOS>'])\n",
        "    return ids\n",
        "\n",
        "print(f\"encode_token('alma')= {encode_token('alma')}\")\n",
        "print(f\"vocab['<UNK>'] ={vocab['<UNK>']}\")\n",
        "print(f\"encode_token('ALMA') = {encode_token('ALMA')}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encode_token('alma')= [23, 28, 21, 38, 28, 4]\n",
            "vocab['<UNK>'] =15\n",
            "encode_token('ALMA') = [23, 15, 15, 15, 15, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "u2gqoL6lVpsH",
        "outputId": "a0a830e0-d4c1-4eed-8b02-2d65ee47f5ca"
      },
      "source": [
        "train_df['encoded'] = train_df.infl.apply(encode_token)\n",
        "dev_df['encoded'] = dev_df.infl.apply(encode_token)\n",
        "test_df['encoded'] = test_df.infl.apply(encode_token)\n",
        "train_df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>infl</th>\n",
              "      <th>tags</th>\n",
              "      <th>target</th>\n",
              "      <th>encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kiemelkedik</td>\n",
              "      <td>kiemelkedtek</td>\n",
              "      <td>V;IND;PST;INDF;3;PL</td>\n",
              "      <td>IND</td>\n",
              "      <td>[23, 17, 5, 32, 38, 32, 21, 17, 32, 10, 6, 32,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>elkényeztet</td>\n",
              "      <td>elkényeztette</td>\n",
              "      <td>V;IND;PST;DEF;3;SG</td>\n",
              "      <td>IND</td>\n",
              "      <td>[23, 32, 21, 17, 11, 9, 39, 32, 34, 6, 32, 6, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>latol</td>\n",
              "      <td>latolják</td>\n",
              "      <td>V;SBJV;PRS;DEF;3;PL</td>\n",
              "      <td>SBJV</td>\n",
              "      <td>[23, 21, 28, 6, 8, 21, 36, 26, 17, 4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vizionál</td>\n",
              "      <td>vizionáltunk</td>\n",
              "      <td>V;IND;PST;INDF;1;PL</td>\n",
              "      <td>IND</td>\n",
              "      <td>[23, 13, 5, 34, 5, 8, 9, 26, 21, 6, 7, 9, 17, 4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>felkér</td>\n",
              "      <td>felkér</td>\n",
              "      <td>V;IND;PRS;INDF;3;SG</td>\n",
              "      <td>IND</td>\n",
              "      <td>[23, 3, 32, 21, 17, 11, 35, 4]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         lemma  ...                                            encoded\n",
              "0  kiemelkedik  ...  [23, 17, 5, 32, 38, 32, 21, 17, 32, 10, 6, 32,...\n",
              "1  elkényeztet  ...  [23, 32, 21, 17, 11, 9, 39, 32, 34, 6, 32, 6, ...\n",
              "2        latol  ...              [23, 21, 28, 6, 8, 21, 36, 26, 17, 4]\n",
              "3     vizionál  ...   [23, 13, 5, 34, 5, 8, 9, 26, 21, 6, 7, 9, 17, 4]\n",
              "4       felkér  ...                     [23, 3, 32, 21, 17, 11, 35, 4]\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0_J4I9DVpsH",
        "outputId": "3f139620-bd91-4ba5-bdde-9efeae3a6931"
      },
      "source": [
        "maxlen = train_df.encoded.apply(len).max()\n",
        "print(maxlen)\n",
        "\n",
        "def pad_sequence(sequence):\n",
        "    if len(sequence) > maxlen:\n",
        "        return sequence[:maxlen]\n",
        "    return sequence + [vocab['<PAD>'] for _ in range(maxlen-len(sequence))]\n",
        "\n",
        "print(pad_sequence([1, 2, 3]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48\n",
            "[1, 2, 3, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeL1jIRjVpsH",
        "outputId": "ab0bf4af-8330-479c-9f33-46ad45d1f2bf"
      },
      "source": [
        "train_df['padded'] = train_df.encoded.apply(pad_sequence)\n",
        "dev_df['padded'] = dev_df.encoded.apply(pad_sequence)\n",
        "test_df['padded'] = test_df.encoded.apply(pad_sequence)\n",
        "\n",
        "train_df['padded'].apply(len).value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48    1000\n",
              "Name: padded, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z2XydEHVpsH"
      },
      "source": [
        "train_df['seqlen'] = train_df.encoded.apply(len)\n",
        "dev_df['seqlen'] = dev_df.encoded.apply(len)\n",
        "test_df['seqlen'] = test_df.encoded.apply(len)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbRKUTzUVpsI",
        "outputId": "7751dd4e-9506-46bb-a3fa-3ae48b41cfc9"
      },
      "source": [
        "label_to_id = {label: i for i, label in enumerate(train_df.target.unique())}\n",
        "label_to_id"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'COND': 2, 'IND': 0, 'SBJV': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44bPbLnCVpsI"
      },
      "source": [
        "train_df['label'] = train_df.target.apply(lambda c: label_to_id[c])\n",
        "dev_df['label'] = dev_df.target.apply(lambda c: label_to_id[c])\n",
        "test_df['label'] = test_df.target.apply(lambda c: label_to_id[c])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YekgrKk3VpsI"
      },
      "source": [
        "# Creating tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EULWIOmsVpsJ",
        "outputId": "affa1089-fd49-45c3-93d0-c97d6806e1ff"
      },
      "source": [
        "X_train = torch.from_numpy(np.array(list(train_df.padded)))\n",
        "y_train = torch.LongTensor(train_df.label.values)\n",
        "seqlen_train = torch.LongTensor(train_df.seqlen.values)\n",
        "print(f\"X_train.size() = {X_train.size()},\\ny_train.size() ={y_train.size()}\\nseqlen_train.size() = {seqlen_train.size()}\\n\")\n",
        "\n",
        "X_dev = torch.from_numpy(np.array(list(dev_df.padded)))\n",
        "y_dev = torch.LongTensor(dev_df.label.values)\n",
        "seqlen_dev = torch.LongTensor(dev_df.seqlen.values)\n",
        "print(f\"X_dev.size() = {X_dev.size()},\\ny_dev.size() = {y_dev.size()}\\nseqlen_dev.size() = {seqlen_dev.size()}\\n\")\n",
        "\n",
        "X_test = torch.from_numpy(np.array(list(test_df.padded)))\n",
        "y_test = torch.LongTensor(test_df.label.values)\n",
        "seqlen_test = torch.LongTensor(test_df.seqlen.values)\n",
        "print(f\"X_test.size() = {X_test.size()},\\ny_test.size() ={y_test.size()}\\nseqlen_test.size() = {seqlen_test.size()}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.size() = torch.Size([1000, 48]),\n",
            "y_train.size() =torch.Size([1000])\n",
            "seqlen_train.size() = torch.Size([1000])\n",
            "\n",
            "X_dev.size() = torch.Size([200, 48]),\n",
            "y_dev.size() = torch.Size([200])\n",
            "seqlen_dev.size() = torch.Size([200])\n",
            "\n",
            "X_test.size() = torch.Size([200, 48]),\n",
            "y_test.size() =torch.Size([200])\n",
            "seqlen_test.size() = torch.Size([200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FLDZS4zVpsJ"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_VUEonzVpsJ"
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.dense = nn.Linear(hidden_size * 2, output_size)\n",
        "        \n",
        "    # the input signature of forward changes\n",
        "    def forward(self, sequences, sequence_lens):\n",
        "        embedded = self.embedding(sequences)\n",
        "        \n",
        "        # THIS IS THE MODIFIED PART\n",
        "        # returns a PackedSequence object\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            embedded,\n",
        "            sequence_lens,\n",
        "            enforce_sorted=False,\n",
        "            batch_first=True)\n",
        "        packed_outputs, (h, c) = self.lstm(packed)\n",
        "        # extract LSTM outputs (not used here)\n",
        "        lstm_outputs, lens = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
        "        \n",
        "        h = torch.cat((h[0], h[1]), dim=-1)\n",
        "        output = self.dense(h)\n",
        "        return output"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WYpsARDVpsK",
        "outputId": "49da322b-9466-4720-873d-a2b57df1a850"
      },
      "source": [
        "input_size = len(vocab)\n",
        "embedding_size = 30\n",
        "hidden_size = 64\n",
        "output_size = train_df.label.nunique()\n",
        "\n",
        "model = LSTMClassifier(input_size, embedding_size, hidden_size, output_size)\n",
        "model\n",
        "print(output_size)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nae38z7lVpsK"
      },
      "source": [
        "# Batching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luX2M2ukVpsK"
      },
      "source": [
        "class BatchedIterator:\n",
        "    def __init__(self, *tensors, batch_size):\n",
        "        # all tensors must have the same first dimension\n",
        "        assert len(set(len(tensor) for tensor in tensors)) == 1\n",
        "        self.tensors = tensors\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    def iterate_once(self):\n",
        "        num_data = len(self.tensors[0])\n",
        "        for start in range(0, num_data, self.batch_size):\n",
        "            end = start + self.batch_size\n",
        "            yield tuple(tensor[start:end] for tensor in self.tensors)"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpKNDhFsVpsK"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9KeAn7zVpsK"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIBkPZdLVpsL"
      },
      "source": [
        "num_epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "metrics = defaultdict(list)\n",
        "train_iter = BatchedIterator(X_train, seqlen_train, y_train, batch_size=batch_size)"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AmSFFs66VpsL",
        "outputId": "c8f4faab-726b-4e62-e170-b66676ef91e7"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    # Training loop\n",
        "  \n",
        "    for X_batch, seqlen_batch, y_batch in train_iter.iterate_once():\n",
        "        #y_out = model(X_batch, seqlen_batch)\n",
        "\n",
        "        # FOR TASK 1:\n",
        "        \n",
        "        y_out = model(X_batch)\n",
        "        # FOR TASK 1:\n",
        "        \n",
        "        # To understand the ouput of the model:\n",
        "        # y_out.shape = [batch_size, output_size] # output_size = number of labels\n",
        "        #print(f'y_out.shape= {y_out.shape} \\ny_batch.shape= {y_batch.shape} ')\n",
        "\n",
        "        #print(f'y_out.shape= {y_out.shape} \\ny_batch.shape= {y_batch.shape} ')\n",
        "        loss = criterion(y_out, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    model.eval()  # or model.train(False)\n",
        "    # Train and dev loss at the end of the epoch\n",
        "    #FOR BEGINING (TESTING BEFORE RUNNING TASK 1)\n",
        "    #y_out = model(X_train, seqlen_train)\n",
        "    #FOR BEGINING (TESTING BEFORE RUNNING TASK 1)\n",
        "\n",
        "    # FOR TASK 1:\n",
        "    y_out = model(X_train)\n",
        "    # FOR TASK 1:\n",
        "\n",
        "    train_loss = criterion(y_out, y_train).item()\n",
        "    metrics['train_loss'].append(train_loss)\n",
        "    labels = y_out.argmax(axis=1)\n",
        "    train_accuracy = (torch.eq(y_train, labels).sum() / float(labels.size(0))).item()\n",
        "    metrics['train_accuracy'].append(train_accuracy)\n",
        "    \n",
        "    #FOR BEGINING (TESTING BEFORE RUNNING TASK 1)\n",
        "    #y_out = model(X_dev, seqlen_dev)\n",
        "    #FOR BEGINING (TESTING BEFORE RUNNING TASK 1)\n",
        "    # FOR TASK 1:\n",
        "    y_out = model(X_dev)\n",
        "    # FOR TASK 1:\n",
        "\n",
        "    dev_loss = criterion(y_out, y_dev).item()\n",
        "    metrics['dev_loss'].append(dev_loss)\n",
        "    labels = y_out.argmax(axis=1)\n",
        "    dev_accuracy = (torch.eq(y_dev, labels).sum() / float(labels.size(0))).item()\n",
        "    metrics['dev_accuracy'].append(dev_accuracy)\n",
        "    \n",
        "    print(f\"Epoch: {epoch} -- train loss: {train_loss:.3f} - train acc: {train_accuracy:.1%} - \"\n",
        "          f\"dev loss: {dev_loss:.3f} - dev acc: {dev_accuracy:.1%}\")"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([104, 48, 60])\n",
            "src.shape =torch.Size([1000, 48, 60])\n",
            "src.shape =torch.Size([200, 48, 60])\n",
            "Epoch: 0 -- train loss: 1.058 - train acc: 49.6% - dev loss: 1.005 - dev acc: 55.0%\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([104, 48, 60])\n",
            "src.shape =torch.Size([1000, 48, 60])\n",
            "src.shape =torch.Size([200, 48, 60])\n",
            "Epoch: 1 -- train loss: 1.054 - train acc: 49.6% - dev loss: 1.032 - dev acc: 55.0%\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([104, 48, 60])\n",
            "src.shape =torch.Size([1000, 48, 60])\n",
            "src.shape =torch.Size([200, 48, 60])\n",
            "Epoch: 2 -- train loss: 1.044 - train acc: 49.6% - dev loss: 1.002 - dev acc: 55.0%\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([104, 48, 60])\n",
            "src.shape =torch.Size([1000, 48, 60])\n",
            "src.shape =torch.Size([200, 48, 60])\n",
            "Epoch: 3 -- train loss: 1.044 - train acc: 49.6% - dev loss: 1.002 - dev acc: 55.0%\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([104, 48, 60])\n",
            "src.shape =torch.Size([1000, 48, 60])\n",
            "src.shape =torch.Size([200, 48, 60])\n",
            "Epoch: 4 -- train loss: 1.043 - train acc: 49.6% - dev loss: 1.012 - dev acc: 55.0%\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([104, 48, 60])\n",
            "src.shape =torch.Size([1000, 48, 60])\n",
            "src.shape =torch.Size([200, 48, 60])\n",
            "Epoch: 5 -- train loss: 1.043 - train acc: 49.6% - dev loss: 1.004 - dev acc: 55.0%\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([104, 48, 60])\n",
            "src.shape =torch.Size([1000, 48, 60])\n",
            "src.shape =torch.Size([200, 48, 60])\n",
            "Epoch: 6 -- train loss: 1.043 - train acc: 49.6% - dev loss: 1.004 - dev acc: 55.0%\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([104, 48, 60])\n",
            "src.shape =torch.Size([1000, 48, 60])\n",
            "src.shape =torch.Size([200, 48, 60])\n",
            "Epoch: 7 -- train loss: 1.043 - train acc: 49.6% - dev loss: 1.008 - dev acc: 55.0%\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([104, 48, 60])\n",
            "src.shape =torch.Size([1000, 48, 60])\n",
            "src.shape =torch.Size([200, 48, 60])\n",
            "Epoch: 8 -- train loss: 1.042 - train acc: 49.6% - dev loss: 1.005 - dev acc: 55.0%\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n",
            "src.shape =torch.Size([128, 48, 60])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-222-176e5083b209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# FOR TASK 1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0my_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# FOR TASK 1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-218-63b380a9fa91>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'src.shape ={src.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mfinal_output\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0msrc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKzidQUQVpsL"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "## Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "jhO2DKa0VpsM",
        "outputId": "b034e1eb-3980-4ead-8557-ee7ac675c4df"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
        "\n",
        "sns.lineplot(data=metrics['train_loss'], ax=ax[0], label='train loss')\n",
        "sns.lineplot(data=metrics['dev_loss'], ax=ax[0], label='dev loss')\n",
        "\n",
        "sns.lineplot(data=metrics['train_accuracy'], ax=ax[1], label='train acc')\n",
        "sns.lineplot(data=metrics['dev_accuracy'], ax=ax[1], label='dev acc')"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe9da707550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IablMGf9VpsM"
      },
      "source": [
        "## Test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97e5_5OTVpsM",
        "outputId": "00b18569-dc8f-4f7b-ee61-06665a537892"
      },
      "source": [
        "logits = model(X_test, seqlen_test)\n",
        "test_prediction = logits.argmax(axis=1)\n",
        "test_accuracy = torch.sum(torch.eq(test_prediction, y_test)) / float(test_prediction.size(0))\n",
        "print(f\"Test accuracy: {test_accuracy:.1%}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 95.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-4d6fyYVpsM"
      },
      "source": [
        "## Error analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5wMhEDCVpsN"
      },
      "source": [
        "test_df['prediction'] = test_prediction"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mfBwT4aVpsN"
      },
      "source": [
        "id_to_label = {i: l for l, i in label_to_id.items()}\n",
        "test_df['predicted_target'] = test_df['prediction'].apply(lambda id_: id_to_label[id_])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "QfZMZMuNVpsN",
        "outputId": "e024c046-64c2-4bae-a5f3-6edf7611e05b"
      },
      "source": [
        "incorrect = test_df[test_df.prediction != test_df.label][['infl', 'target', 'predicted_target']]\n",
        "incorrect.sample(min(len(incorrect), 20))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>infl</th>\n",
              "      <th>target</th>\n",
              "      <th>predicted_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>csöpögjön</td>\n",
              "      <td>SBJV</td>\n",
              "      <td>COND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>lemész|or|</td>\n",
              "      <td>IND</td>\n",
              "      <td>SBJV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>legyőznek</td>\n",
              "      <td>IND</td>\n",
              "      <td>SBJV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>ágyazza</td>\n",
              "      <td>SBJV</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>kacagjátok</td>\n",
              "      <td>SBJV</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>vacsorázzuk</td>\n",
              "      <td>SBJV</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>felfrissítették</td>\n",
              "      <td>IND</td>\n",
              "      <td>SBJV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>kóstolja</td>\n",
              "      <td>IND</td>\n",
              "      <td>SBJV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>fakasszátok</td>\n",
              "      <td>SBJV</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>stagnáljatok</td>\n",
              "      <td>SBJV</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                infl target predicted_target\n",
              "109        csöpögjön   SBJV             COND\n",
              "112       lemész|or|    IND             SBJV\n",
              "24         legyőznek    IND             SBJV\n",
              "133          ágyazza   SBJV              IND\n",
              "173       kacagjátok   SBJV              IND\n",
              "11       vacsorázzuk   SBJV              IND\n",
              "134  felfrissítették    IND             SBJV\n",
              "159         kóstolja    IND             SBJV\n",
              "197      fakasszátok   SBJV              IND\n",
              "38      stagnáljatok   SBJV              IND"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCFdZVIIVpsN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mmOfMwsVpsO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSuy-M7TX2je"
      },
      "source": [
        ""
      ]
    }
  ]
}