{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python and Natural Language Technologies\n",
    "\n",
    "__Lecture 8, Sequence modeling__\n",
    "\n",
    "__March 30, 2021__\n",
    "\n",
    "__Judit √Åcs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "1. Overview of sequence modeling\n",
    "    - Sequence elements\n",
    "    - Types of models\n",
    "    - Some applications\n",
    "2. A bare bone sequence classification example\n",
    "    - Cover the details of modeling and training\n",
    "    - Data preparation with Pandas\n",
    "    - Training on a small task that runs quickly on a laptop CPU \n",
    "    - Use advanced Python features instead of `torchtext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard `torch` imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence elements\n",
    "\n",
    "We deal with sequences in NLP:\n",
    "- a token is a sequence of characters/morphemes\n",
    "- a sentence is a sequence of tokens\n",
    "- a paragraph is a sequence of sentences\n",
    "- a dialogue is a sequence of utterances\n",
    "- etc.\n",
    "\n",
    "What are the elements of these sequences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words\n",
    "\n",
    "Pros:\n",
    "\n",
    "- More or less well-defined in most languages\n",
    "- Relatively short sequences (a sentence is rarely longer than 30 tokens)\n",
    "\n",
    "Cons:\n",
    "- Difficult tokenization in some languages\n",
    "- Large vocabulary (100,000+ easily)\n",
    "- Out-of-vocabulary words are always there regardless of the size of the vocabulary\n",
    "- Many rare words\n",
    "    - Hapax: a word that only appears once in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characters\n",
    "\n",
    "Pros:\n",
    "- Smaller vocabulary although logographic writing systems (Chinese and Japanese) have thousands of characters\n",
    "- Easy tokenization\n",
    "- Well defined: Unicode symbols\n",
    "\n",
    "Cons:\n",
    "- Long sequences\n",
    "- Too fine-grained, token level information is lost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subwords\n",
    "\n",
    "- Multiple characters but smaller than words\n",
    "- Modern language models use subword vocabularies\n",
    "- We will cover these next week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence classification\n",
    "\n",
    "Assign a single label to the full sequence:\n",
    "\n",
    "<img src=\"img/tikz/abstract_sequence_classification.png\" width=\"350\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Applications__\n",
    "\n",
    "- Topic classification (AG News dataset from Lab 7)\n",
    "- Sentiment analysis: is this sentence or paragraph a positive (1) or a negative (0) review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/tikz/example_sequence_classification.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence tagging\n",
    "\n",
    "Assign a label to each element of the sequence:\n",
    "\n",
    "<img src=\"img/tikz/abstract_sequence_tagging.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Applications__\n",
    "\n",
    "- part-of-speech tagging\n",
    "- named entity recognition (NER)\n",
    "\n",
    "<img src=\"img/tikz/example_sequence_tagging.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq\n",
    "\n",
    "<img src=\"img/tikz/abstract_seq2seq.png\" width=600px>\n",
    "\n",
    "- Maps a source sequence to a target sequence\n",
    "    - Arbitrary length\n",
    "    \n",
    "- Two steps:\n",
    "    1. Encode: create a representation of the source\n",
    "    2. Decode: generate the target representation\n",
    "        - autoregressive: generate tokens from left-to-right one-by-one (condition on the left context)\n",
    "        \n",
    "- Usually implemented as two separate neural networks for example:\n",
    "    - The encoder is a bidirectional LSTM\n",
    "    - The decoder is a unidirectional LSTM\n",
    "    \n",
    "- Applications:\n",
    "    - Neural machine translation\n",
    "    - Morphological inflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention\n",
    "\n",
    "Seq2seq performs poorly in its naive form since the decoder has to generate the whole output based on a single hidden vector that represents the full input sequence.\n",
    "\n",
    "**Attention** gives peak into the input sequence [image source](https://aihub.cloud.google.com/u/0/p/products%2F024b89fd-9bc8-4c24-b8a8-e347479f3270):\n",
    "    \n",
    "<img src=\"img/dl/attention_mechanism.jpg\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other tasks\n",
    "\n",
    "There are many other NLP tasks that are solved with some combination of the above models.\n",
    "\n",
    "- Sentence pair classification: the same as sequence classification except we assign a label to a __pair__ of sentences\n",
    "    - paraphrase identification\n",
    "- Span level tasks\n",
    "- Tree-based tasks\n",
    "    - Universal Dependencies (Lecture 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence classification example\n",
    "\n",
    "We will now train a sequence classification model on Hungarian morphology. This model can be trained on a laptop CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "\n",
    "Neural networks are usually trained with the [backpropagation](https://en.wikipedia.org/wiki/Backpropagation) algorithm.\n",
    "\n",
    "The data flow in neural networks implicitly defines a **computation graph**, this is called **forward pass**.\n",
    "\n",
    "The output is compared against the ground truth or label and the difference or cost is quantified by **loss function** also called **cost function**.\n",
    "\n",
    "If the loss function is differentiable with respect to the parameters, we can compute the gradient w.r.t. to all parameters i.e. we can quantify 'how responsible' a parameter is for the loss using the chain rule. This is called **backpropagation**.\n",
    "\n",
    "An optimizer then updates the parameters. The update is proportional to the gradient. This is called **gradient descent**.\n",
    "\n",
    "More information: [Backpropagation chapter](https://www.deeplearningbook.org/contents/mlp.html#pf25) from [Deep Learning](https://www.deeplearningbook.org/) by Goodfellow, Bengio and Courville\n",
    "\n",
    "We will now discuss the building blocks of the sequence classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `nn.Embedding`\n",
    "\n",
    "`nn.Embedding` maps integers to continuous vectors. Its mandatory parameters are:\n",
    "- `num_embeddings`: the size of the vocabulary\n",
    "- `embedding_dim`: the size of the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0556,  0.4509, -0.8940],\n",
       "        [ 0.8215, -0.9376,  0.7264],\n",
       "        [-0.0556,  0.4509, -0.8940],\n",
       "        [-0.0556,  0.4509, -0.8940]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(5, 3) # (5,3) specifies the num_embedding and embedding_dim respectively, they are hyperparameters => we can specify them by hand.\n",
    "                               # after this command, the 'embedding' already contains 5 row vectors\n",
    "                               # and each of row vector, contains 3 random numbers. \n",
    "                               # the number of row vetors of the embedding is NOT the number of words in a sentence which we would consider as input for the lstm model. \n",
    "\n",
    "embedding(torch.LongTensor([1,4])) # some how like magic functions, callable, this command creates another matrix with its row vectors taken from the 'embedding'\n",
    "                                   # THE RESULT MATRIX has 2 vectors which are taken from the 'embedding', the first vector is the first row vector of the 'embedding'\n",
    "                                   # the second vector is the 4th row vector of the 'embedding' \n",
    "                                   # 1 and 4 are all indexes of the embedding (the 'embedding' object has num_embedding is 5 => the range is 5 => the indexes from 0 to 4)\n",
    "                                   # results: [[ 1.1923,  0.0404,  1.4719],\n",
    "                                   # [-0.8079, -0.7790,  0.2477]],...] \n",
    "                                   # [ 1.1923,  0.0404,  1.4719] shows the first element (because the index is 1) of the 'embedding', it has 3 columns because the embedding_size is 3.\n",
    "                                   # [-0.8079, -0.7790,  0.2477] shows the fourth element (because the index is 4) of the 'embedding', it has 3 columns because the embedding_size is 3.\n",
    "\n",
    "embedding(torch.LongTensor([1,4,1,1])) # this creates a matrix of 4 vectors,\n",
    "                                       # the first, third and fourth vectors have their values as the first row vector of 'embedding'\n",
    "                                       # the second has its values as the 4th row vector.\n",
    "# embedding(torch.LongTensor([1, 5]))  # raises IndexError because 5 is out of range, our specified index of 'embedding' is (5,3), so the vocab size is 5 => the index is from 0 to 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works with higher order tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor.size() = torch.Size([5, 2])\n",
      "emb.size() = torch.Size([5, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0556,  0.4509, -0.8940],\n",
       "         [ 2.8806,  0.3378, -0.7264]],\n",
       "\n",
       "        [[-1.3386,  0.1491, -0.6072],\n",
       "         [-0.0556,  0.4509, -0.8940]],\n",
       "\n",
       "        [[-0.0556,  0.4509, -0.8940],\n",
       "         [ 2.8806,  0.3378, -0.7264]],\n",
       "\n",
       "        [[-1.3386,  0.1491, -0.6072],\n",
       "         [-0.0556,  0.4509, -0.8940]],\n",
       "\n",
       "        [[-1.3386,  0.1491, -0.6072],\n",
       "         [-0.0556,  0.4509, -0.8940]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.LongTensor(\n",
    "    [[1, 2], [0, 1], [1, 2], [0, 1], [0, 1]]\n",
    ")\n",
    "emb = embedding(input_tensor)\n",
    "print(f\"{input_tensor.size() = }\")\n",
    "print(f\"{emb.size() = }\")\n",
    "emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding's parameters can be listed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# the values in each embedding row vector represents a weight in the machine learning (deeplearning) model,\n",
    "# which is updated by backpropagation procedure. \n",
    "\n",
    "for pname, param in embedding.named_parameters():\n",
    "    print(pname, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `nn.LSTM`\n",
    "\n",
    "LSTM is the most popular recurrent cell that takes a sequence as an input and processes it one by one while updating its hidden state. Its parameters are (from [here](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html?highlight=lstm#torch.nn.LSTM)):\n",
    "- `input_size`: The number of expected features in the input x\n",
    "- `hidden_size`: The number of features in the hidden state h\n",
    "- `num_layers`: Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1\n",
    "- `bias`: If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "- `batch_first`: If True, then the input and output tensors are provided as (batch, seq, feature). Default: False\n",
    "- `dropout`: If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "- `bidirectional`: If True, becomes a bidirectional LSTM. Default: False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(5, 12, batch_first=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = nn.LSTM(5, 12, num_layers=1, bidirectional=False, batch_first=True, dropout=0) # list of parameters of nn.LSTM are listed in the above cell\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([48, 5])\n",
      "weight_hh_l0 torch.Size([48, 12])\n",
      "bias_ih_l0 torch.Size([48])\n",
      "bias_hh_l0 torch.Size([48])\n"
     ]
    }
   ],
   "source": [
    "# these are the trained parameter of the machine learning model by backpropagation procedure.\n",
    "for pname, param in lstm.named_parameters():\n",
    "    print(pname, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its input **must** be 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_tensor = torch.rand((3, 2)) # a 2D input\n",
    "\n",
    "# with the 2D input_tensor:\n",
    "#lstm(input_tensor)  # raises RunTimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.size() = torch.Size([3, 2, 12])\n",
      "h.size() = torch.Size([1, 3, 12])\n",
      "c.size() = torch.Size([1, 3, 12])\n"
     ]
    }
   ],
   "source": [
    "# batch_size X sequence_length X input_size (The number of expected features in the input x)\n",
    "# 3 X 2 X 5\n",
    "input_tensor = torch.rand((3, 2, 5)) \n",
    "\n",
    "\n",
    "outputs, (h, c) = lstm(input_tensor) # \n",
    "                                     # 'outputs' is the intermedietary outputs of each step,\n",
    "                                     # there are 2 steps because the sequence_length is 2  \n",
    "                                     #  check the 'outputs' size: outputs.size() = torch.Size([3, 2, 12])\n",
    "                                     # 3: batch size\n",
    "                                     # 2: sequence_length \n",
    "                                     # 12: hidden size (number of parameters inside a lstm cell? ) of lstm.\n",
    "                                     # 'h' the output weight of final (output) cell in the model made of the lstm\n",
    "                                     # 'c' the output value of final (output) cell in the model made of the lstm\n",
    "print(f\"{outputs.size() = }\")\n",
    "print(f\"{h.size() = }\")\n",
    "print(f\"{c.size() = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice we generally use bidirectional LSTMs, which are implemented as two unidirectional LSTMs.\n",
    "\n",
    "`h` and `c` are now the final states of both unidirectional LSTMs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.size() = torch.Size([3, 2, 24])\n",
      "h.size() = torch.Size([2, 3, 12])\n",
      "c.size() = torch.Size([2, 3, 12])\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(5, 12, num_layers=1, bidirectional=True, batch_first=True, dropout=0)\n",
    "\n",
    "input_tensor = torch.rand((3, 2, 5))\n",
    "outputs, (h, c) = lstm(input_tensor)\n",
    "\n",
    "#h.size() = torch.Size([2, 3, 12]); the first param is 2 because we define the bidirectional=True\n",
    "                                  # it is like concatenation of 2 unidirectional LSTMs\n",
    "\n",
    "print(f\"{outputs.size() = }\")\n",
    "print(f\"{h.size() = }\")\n",
    "print(f\"{c.size() = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining `nn.LSTM` with `nn.Embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "vocab_size = 10\n",
    "embedding_size = 5\n",
    "lstm_hidden_size = 6\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "lstm = nn.LSTM(embedding_size, lstm_hidden_size, num_layers=1, bidirectional=True, batch_first=True, dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 5, 6, 0],\n",
       "        [7, 7, 6, 2],\n",
       "        [1, 5, 9, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input parameters (not that these are independent of the model)\n",
    "batch_size = 3\n",
    "sequence_length = 4\n",
    "\n",
    "input_ids = torch.randint(vocab_size, (batch_size, sequence_length))\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids.size() = torch.Size([3, 4])\n",
      "embedded.size() = torch.Size([3, 4, 5])\n",
      "outputs.size() = torch.Size([3, 4, 12])\n",
      "h.size() = torch.Size([2, 3, 6])\n",
      "c.size() = torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "embedded = embedding(input_ids)\n",
    "outputs, (h, c) = lstm(embedded)\n",
    "\n",
    "print(f\"{input_ids.size() = }\")\n",
    "print(f\"{embedded.size() = }\")\n",
    "print(f\"{outputs.size() = }\") #outputs.size() = torch.Size([3, 4, 12]), the 12 = 6+6, because the hidden_size is 6 and lstm is bidirectional => 6 for each direction => 2 directions are 12\n",
    "print(f\"{h.size() = }\")\n",
    "print(f\"{c.size() = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `nn.Linear` (another type of cell which is different from LSTM cell)\n",
    "\n",
    "`nn.Linear` implements a matrix projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=5, bias=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = nn.Linear(3, 5)\n",
    "dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([5, 3])\n",
      "bias torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for pname, param in dense.named_parameters():\n",
    "    print(pname, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.size() = torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.rand((2, 3))\n",
    "output = dense(input_tensor)\n",
    "print(f\"{output.size() = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inner dimensions must match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_tensor = torch.rand((2, 4)) # because the input feature of the dense is 3 but here 4 is provided \n",
    "# => output = dense(input_tensor)  # raises RuntimeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `LSTMClassifier` class\n",
    "\n",
    "We can now define our own LSTM sequence classifier model.\n",
    "\n",
    "All PyTorch modules must subclass `nn.Module` (or one of its subclasses) and call `init` before any attribute assignment.\n",
    "\n",
    "There two methods we have to implement:\n",
    "- `__init__`: defines submodules. These constitute the nodes _computation graph_.\n",
    "- `forward` implements the forward pass of the module. This is how we map the input to the output. The way we pass the input through the module implicitly builds a directed graph of the submodules named _computation graph_.\n",
    "\n",
    "The backward pass is automatically handled by PyTorch but it can be overriden by implementind the `backward` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3148, -0.1321, -0.6120,  0.2341],\n",
       "        [-0.3148, -0.1321, -0.6120,  0.2341],\n",
       "        [-0.3417, -0.2198, -0.5960,  0.1149],\n",
       "        [-0.3190, -0.0557, -0.3756,  0.1535]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMClassifier(nn.Module): # inherits from nn.Module, which is used to build a module in the machine learning (deeplearning) model\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size): # output_size is number of labels (or targeted classes) we want to have\n",
    "        super().__init__()\n",
    "        \n",
    "        # the below commands specifies all the parameters of the model:\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True, # to specify whether the firs parameter of lstm() is batch_size or sequence_length\n",
    "        ) # a LSTM layer followed by a linear layer which is specified below:\n",
    "        \n",
    "        # the linear layer:\n",
    "        self.dense = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "    def forward(self, sequences):\n",
    "        # sequences: batch_size X sequence_length\n",
    "        embedded = self.embedding(sequences)\n",
    "        \n",
    "        # lstm_outputs: batch_size X sequence_length X 2*hidden_size\n",
    "        # h: 2 X batch_size X hidden_size\n",
    "        # c: 2 X batch_size X hidden_size\n",
    "        lstm_outputs, (h, c) = self.lstm(embedded)\n",
    "        \n",
    "        # h: batch_size X 2*hidden_size\n",
    "        h = torch.cat((h[0], h[1]), dim=-1)\n",
    "        \n",
    "        # output: batch_size X output_size\n",
    "        output = self.dense(h)\n",
    "        return output\n",
    "        \n",
    "        \n",
    "toy_classifier = LSTMClassifier(3, 110, 5, 4) # 4 specifies how many columns (labels) we will have in the output matrix\n",
    "toy_input = torch.LongTensor([\n",
    "    [0, 1, 0, 2], # the same as the second row vector => their outputs must be the same\n",
    "    [0, 1, 0, 2],\n",
    "    [0, 0, 0, 2],\n",
    "    [1, 1, 2, 0],\n",
    "])\n",
    "toy_classifier(toy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under the hood\n",
    "\n",
    "PyTorch registers every attribute in `__init__` that is an instance of `nn.Module` in the parameters of the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight torch.Size([3, 110])\n",
      "lstm.weight_ih_l0 torch.Size([20, 110])\n",
      "lstm.weight_hh_l0 torch.Size([20, 5])\n",
      "lstm.bias_ih_l0 torch.Size([20])\n",
      "lstm.bias_hh_l0 torch.Size([20])\n",
      "lstm.weight_ih_l0_reverse torch.Size([20, 110])\n",
      "lstm.weight_hh_l0_reverse torch.Size([20, 5])\n",
      "lstm.bias_ih_l0_reverse torch.Size([20])\n",
      "lstm.bias_hh_l0_reverse torch.Size([20])\n",
      "dense.weight torch.Size([4, 10])\n",
      "dense.bias torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for pname, param in toy_classifier.named_parameters():\n",
    "    print(pname, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is **not** true for lists and other complex data types. PyTorch does not attempt to traverse them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SimpleModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(12, 4), nn.Linear(15, 9)]\n",
    "        \n",
    "for pname, param in SimpleModule().named_parameters():\n",
    "    print(pname, param.size()) # prints nothing because the self.layers = [nn.Linear(12, 4), nn.Linear(15, 9)]\n",
    "    # is not processed by Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is `nn.ModuleList` or `nn.Sequential`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: layers.0.weight, size: torch.Size([4, 12])\n",
      "name: layers.0.bias, size: torch.Size([4])\n",
      "name: layers.1.weight, size: torch.Size([9, 15])\n",
      "name: layers.1.bias, size: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "class SimpleModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(12, 4), nn.Linear(15, 9)])\n",
    "        \n",
    "for param in SimpleModule().named_parameters():\n",
    "    print(f\"name: {param[0]}, size: {param[1].size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Sequential` chains multiple modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight torch.Size([4, 12])\n",
      "layers.0.bias torch.Size([4])\n",
      "layers.2.weight torch.Size([9, 15])\n",
      "layers.2.bias torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "class SimpleModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(12, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15, 9),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = self.layers(out)\n",
    "        return out\n",
    "    \n",
    "        \n",
    "for pname, param in SimpleModule().named_parameters():\n",
    "    print(pname, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Please run `08_Prepare_unimorph_data.ipynb` to download and preprocess the dataset for this example.\n",
    "\n",
    "We will now train a small classifier that predicts the case of Hungarian nouns. Hungarian has a rich case system in place of prefixes used by English. Some examples are:\n",
    "\n",
    "| Case | Hungarian | English |\n",
    "| ---- | ---- | ---- |\n",
    "| Nominative | h√°z | house |\n",
    "| Instrumental | h√°zzal | with (a) house |\n",
    "| Ablative  | h√°zt√≥l | from at (a) house |\n",
    "| Elativus  | h√°zb√≥l | from inside (a) house |\n",
    "\n",
    "\n",
    "We will train a character-level model that predicts the case based on the word form. This is an easy task since most of the time the grammatical case is obvious from the last 3 characters of the word.\n",
    "\n",
    "Our model looks like this:\n",
    "\n",
    "<img src=\"img/tikz/hungarian_case_lstm.png\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343484 42752 43157\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>infl</th>\n",
       "      <th>tags</th>\n",
       "      <th>pos</th>\n",
       "      <th>case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gravit√°ci√≥</td>\n",
       "      <td>gravit√°ci√≥n</td>\n",
       "      <td>N;ON+ESS;SG</td>\n",
       "      <td>N</td>\n",
       "      <td>ON+ESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gravit√°ci√≥</td>\n",
       "      <td>gravit√°ci√≥k√©nt</td>\n",
       "      <td>N;FRML;SG</td>\n",
       "      <td>N</td>\n",
       "      <td>FRML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gravit√°ci√≥</td>\n",
       "      <td>gravit√°ci√≥kban</td>\n",
       "      <td>N;IN+ESS;PL</td>\n",
       "      <td>N</td>\n",
       "      <td>IN+ESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gravit√°ci√≥</td>\n",
       "      <td>gravit√°ci√≥khoz</td>\n",
       "      <td>N;AT+ALL;PL</td>\n",
       "      <td>N</td>\n",
       "      <td>AT+ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gravit√°ci√≥</td>\n",
       "      <td>gravit√°ci√≥</td>\n",
       "      <td>N;NOM;SG</td>\n",
       "      <td>N</td>\n",
       "      <td>NOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lemma            infl         tags pos    case\n",
       "0  gravit√°ci√≥     gravit√°ci√≥n  N;ON+ESS;SG   N  ON+ESS\n",
       "1  gravit√°ci√≥  gravit√°ci√≥k√©nt    N;FRML;SG   N    FRML\n",
       "2  gravit√°ci√≥  gravit√°ci√≥kban  N;IN+ESS;PL   N  IN+ESS\n",
       "3  gravit√°ci√≥  gravit√°ci√≥khoz  N;AT+ALL;PL   N  AT+ALL\n",
       "4  gravit√°ci√≥      gravit√°ci√≥     N;NOM;SG   N     NOM"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_table(\"data/unimorph/hun_train.tsv\")\n",
    "dev_df = pd.read_table(\"data/unimorph/hun_dev.tsv\")\n",
    "test_df = pd.read_table(\"data/unimorph/hun_test.tsv\")\n",
    "print(len(train_df), len(dev_df), len(test_df))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling\n",
    "\n",
    "We don't need much data to train the model, let's downsample it and train on a small subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sample(1000, random_state=1).reset_index(drop=True)\n",
    "dev_df = dev_df.sample(200, random_state=1).reset_index(drop=True)\n",
    "test_df = test_df.sample(200, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the vocabulary\n",
    "\n",
    "We need to map each character to an integer id. For this we need to define a `char->int` mapping that is as big as the alphabet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = set()\n",
    "for token in train_df.infl: # should use train set not with test set to have the most accurate assessment of our model\n",
    "    alphabet |= set(token)\n",
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and some extra symbols:\n",
    "\n",
    "1. PAD: used as filler symbols for shorter sequences (see later)\n",
    "2. BOS: beginning-of-sequence. Indicates the start of the sequence.\n",
    "2. EOS: end-of-sequence. Indicates the end of the sequence.\n",
    "2. UNK: unknown. Symbols (or words) that fall out of the vocabulary are replaced with this symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alphabet.add('<PAD>')\n",
    "alphabet.add('<BOS>')\n",
    "alphabet.add('<EOS>')\n",
    "alphabet.add('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': 0,\n",
       " 'x': 1,\n",
       " 'F': 2,\n",
       " '√©': 3,\n",
       " 'w': 4,\n",
       " '≈±': 5,\n",
       " 'v': 6,\n",
       " '-': 7,\n",
       " 'g': 8,\n",
       " 'y': 9,\n",
       " '√º': 10,\n",
       " 'f': 11,\n",
       " 'z': 12,\n",
       " 'D': 13,\n",
       " '<BOS>': 14,\n",
       " '√∫': 15,\n",
       " '√≠': 16,\n",
       " 'P': 17,\n",
       " 'r': 18,\n",
       " 'a': 19,\n",
       " 'c': 20,\n",
       " 'd': 21,\n",
       " 's': 22,\n",
       " 'j': 23,\n",
       " 'l': 24,\n",
       " 'o': 25,\n",
       " 'b': 26,\n",
       " 'm': 27,\n",
       " '<PAD>': 28,\n",
       " '√∂': 29,\n",
       " '√°': 30,\n",
       " 'h': 31,\n",
       " 'i': 32,\n",
       " 'C': 33,\n",
       " '≈ë': 34,\n",
       " 'u': 35,\n",
       " ' ': 36,\n",
       " 'k': 37,\n",
       " '√≥': 38,\n",
       " 'p': 39,\n",
       " '<EOS>': 40,\n",
       " '|': 41,\n",
       " 'n': 42,\n",
       " '<UNK>': 43,\n",
       " '.': 44,\n",
       " 't': 45}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {symbol: i for i, symbol in enumerate(alphabet)}\n",
    "len(vocab)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_token('alma') = [14, 19, 24, 27, 19, 40]\n",
      "vocab['<UNK>'] = 43\n",
      "encode_token('ALMA') = [14, 43, 43, 43, 43, 40]\n"
     ]
    }
   ],
   "source": [
    "def encode_token(token):\n",
    "    ids = []\n",
    "    ids.append(vocab['<BOS>'])\n",
    "    # dev and test might contain characters outside the alphabet\n",
    "    ids.extend(vocab.get(c, vocab['<UNK>']) for c in token)# if the word is in the vocabulary, we get its index as value, if it is not, we get UNK as value\n",
    "    ids.append(vocab['<EOS>'])\n",
    "    return ids\n",
    "\n",
    "print(f\"{encode_token('alma') = }\") # result: [14, 19, 24, 27, 19, 40] ; 14  is the BOS and 40 is the EOS\n",
    "print(f\"{vocab['<UNK>'] = }\")\n",
    "print(f\"{encode_token('ALMA') = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>infl</th>\n",
       "      <th>tags</th>\n",
       "      <th>pos</th>\n",
       "      <th>case</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f√ºlbem√°sz√≥</td>\n",
       "      <td>f√ºlbem√°sz√≥k√©nt</td>\n",
       "      <td>N;FRML;SG</td>\n",
       "      <td>N</td>\n",
       "      <td>FRML</td>\n",
       "      <td>[14, 11, 10, 24, 26, 0, 27, 30, 22, 12, 38, 37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fesz√ºltebb</td>\n",
       "      <td>fesz√ºltebbet</td>\n",
       "      <td>N;ACC;SG</td>\n",
       "      <td>N</td>\n",
       "      <td>ACC</td>\n",
       "      <td>[14, 11, 0, 22, 12, 10, 24, 45, 0, 26, 26, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>olajfa</td>\n",
       "      <td>olajf√°ra</td>\n",
       "      <td>N;ON+ALL;SG</td>\n",
       "      <td>N</td>\n",
       "      <td>ON+ALL</td>\n",
       "      <td>[14, 25, 24, 19, 23, 11, 30, 18, 19, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prostit√∫ci√≥</td>\n",
       "      <td>prostit√∫ci√≥kat</td>\n",
       "      <td>N;ACC;PL</td>\n",
       "      <td>N</td>\n",
       "      <td>ACC</td>\n",
       "      <td>[14, 39, 18, 25, 22, 45, 32, 45, 15, 20, 32, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alt</td>\n",
       "      <td>altt√°</td>\n",
       "      <td>N;TRANS;SG</td>\n",
       "      <td>N</td>\n",
       "      <td>TRANS</td>\n",
       "      <td>[14, 19, 24, 45, 45, 30, 40]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lemma            infl         tags pos    case  \\\n",
       "0   f√ºlbem√°sz√≥  f√ºlbem√°sz√≥k√©nt    N;FRML;SG   N    FRML   \n",
       "1   fesz√ºltebb    fesz√ºltebbet     N;ACC;SG   N     ACC   \n",
       "2       olajfa        olajf√°ra  N;ON+ALL;SG   N  ON+ALL   \n",
       "3  prostit√∫ci√≥  prostit√∫ci√≥kat     N;ACC;PL   N     ACC   \n",
       "4          alt           altt√°   N;TRANS;SG   N   TRANS   \n",
       "\n",
       "                                             encoded  \n",
       "0  [14, 11, 10, 24, 26, 0, 27, 30, 22, 12, 38, 37...  \n",
       "1  [14, 11, 0, 22, 12, 10, 24, 45, 0, 26, 26, 0, ...  \n",
       "2           [14, 25, 24, 19, 23, 11, 30, 18, 19, 40]  \n",
       "3  [14, 39, 18, 25, 22, 45, 32, 45, 15, 20, 32, 3...  \n",
       "4                       [14, 19, 24, 45, 45, 30, 40]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['encoded'] = train_df.infl.apply(encode_token) # apply enode_token function for each value in the column 'infl'\n",
    "dev_df['encoded'] = dev_df.infl.apply(encode_token)\n",
    "test_df['encoded'] = test_df.infl.apply(encode_token)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "\n",
    "The input sequences different in length at the moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='infl', ylabel='count'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=train_df.infl.str.len(), palette='tab10') # find the longest sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lemma                              megk√ºl√∂nb√∂ztethetetlens√©g\n",
       "infl                             megk√ºl√∂nb√∂ztethetetlens√©gig\n",
       "tags                                               N;TERM;SG\n",
       "pos                                                        N\n",
       "case                                                    TERM\n",
       "encoded    [12, 41, 18, 10, 16, 34, 39, 36, 17, 43, 36, 2...\n",
       "Name: 161, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df.infl.str.len().idxmax()] # # find the longest sequence exactly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We append **PAD** symbols to the shorter sequences like this:\n",
    "\n",
    "<img src=\"img/tikz/padding.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "[1, 2, 3, 4, 1, 2, 3, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28]\n"
     ]
    }
   ],
   "source": [
    "maxlen = train_df.encoded.apply(len).max()\n",
    "print(maxlen)\n",
    "\n",
    "def pad_sequence(sequence):\n",
    "    if len(sequence) > maxlen: # must limit every input sequence to the maximum length of the longest sequence in the train dataaset\n",
    "        return sequence[:maxlen]\n",
    "    return sequence + [vocab['<PAD>'] for _ in range(maxlen-len(sequence))]\n",
    "\n",
    "print(pad_sequence([1, 2, 3, 4, 1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29    1000\n",
       "Name: padded, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['padded'] = train_df.encoded.apply(pad_sequence)\n",
    "dev_df['padded'] = dev_df.encoded.apply(pad_sequence)\n",
    "test_df['padded'] = test_df.encoded.apply(pad_sequence)\n",
    "\n",
    "train_df['padded'].apply(len).value_counts() # check the sanity of the pad_sequence function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need the original lengths of each sequence later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we need to store the original sequence length for later usage ? what usage???\n",
    "\n",
    "train_df['seqlen'] = train_df.encoded.apply(len) \n",
    "dev_df['seqlen'] = dev_df.encoded.apply(len)\n",
    "test_df['seqlen'] = test_df.encoded.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing labels\n",
    "\n",
    "There are 18 labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FRML': 0,\n",
       " 'ACC': 1,\n",
       " 'ON+ALL': 2,\n",
       " 'TRANS': 3,\n",
       " 'IN+ALL': 4,\n",
       " 'AT+ALL': 5,\n",
       " 'IN+ESS': 6,\n",
       " 'ON+ABL': 7,\n",
       " 'IN+ABL': 8,\n",
       " 'INST': 9,\n",
       " 'TERM': 10,\n",
       " 'AT+ESS': 11,\n",
       " 'PRP': 12,\n",
       " 'AT+ABL': 13,\n",
       " 'NOM': 14,\n",
       " 'ON+ESS': 15,\n",
       " 'DAT': 16}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id = {label: i for i, label in enumerate(train_df.case.unique())} # labels in every model must start from 0 to n-1\n",
    "label_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a `label` column to each dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['label'] = train_df.case.apply(lambda c: label_to_id[c])\n",
    "dev_df['label'] = dev_df.case.apply(lambda c: label_to_id[c])\n",
    "test_df['label'] = test_df.case.apply(lambda c: label_to_id[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>infl</th>\n",
       "      <th>tags</th>\n",
       "      <th>pos</th>\n",
       "      <th>case</th>\n",
       "      <th>encoded</th>\n",
       "      <th>padded</th>\n",
       "      <th>seqlen</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f√ºlbem√°sz√≥</td>\n",
       "      <td>f√ºlbem√°sz√≥k√©nt</td>\n",
       "      <td>N;FRML;SG</td>\n",
       "      <td>N</td>\n",
       "      <td>FRML</td>\n",
       "      <td>[14, 11, 10, 24, 26, 0, 27, 30, 22, 12, 38, 37...</td>\n",
       "      <td>[14, 11, 10, 24, 26, 0, 27, 30, 22, 12, 38, 37...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fesz√ºltebb</td>\n",
       "      <td>fesz√ºltebbet</td>\n",
       "      <td>N;ACC;SG</td>\n",
       "      <td>N</td>\n",
       "      <td>ACC</td>\n",
       "      <td>[14, 11, 0, 22, 12, 10, 24, 45, 0, 26, 26, 0, ...</td>\n",
       "      <td>[14, 11, 0, 22, 12, 10, 24, 45, 0, 26, 26, 0, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>olajfa</td>\n",
       "      <td>olajf√°ra</td>\n",
       "      <td>N;ON+ALL;SG</td>\n",
       "      <td>N</td>\n",
       "      <td>ON+ALL</td>\n",
       "      <td>[14, 25, 24, 19, 23, 11, 30, 18, 19, 40]</td>\n",
       "      <td>[14, 25, 24, 19, 23, 11, 30, 18, 19, 40, 28, 2...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prostit√∫ci√≥</td>\n",
       "      <td>prostit√∫ci√≥kat</td>\n",
       "      <td>N;ACC;PL</td>\n",
       "      <td>N</td>\n",
       "      <td>ACC</td>\n",
       "      <td>[14, 39, 18, 25, 22, 45, 32, 45, 15, 20, 32, 3...</td>\n",
       "      <td>[14, 39, 18, 25, 22, 45, 32, 45, 15, 20, 32, 3...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alt</td>\n",
       "      <td>altt√°</td>\n",
       "      <td>N;TRANS;SG</td>\n",
       "      <td>N</td>\n",
       "      <td>TRANS</td>\n",
       "      <td>[14, 19, 24, 45, 45, 30, 40]</td>\n",
       "      <td>[14, 19, 24, 45, 45, 30, 40, 28, 28, 28, 28, 2...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lemma            infl         tags pos    case  \\\n",
       "0   f√ºlbem√°sz√≥  f√ºlbem√°sz√≥k√©nt    N;FRML;SG   N    FRML   \n",
       "1   fesz√ºltebb    fesz√ºltebbet     N;ACC;SG   N     ACC   \n",
       "2       olajfa        olajf√°ra  N;ON+ALL;SG   N  ON+ALL   \n",
       "3  prostit√∫ci√≥  prostit√∫ci√≥kat     N;ACC;PL   N     ACC   \n",
       "4          alt           altt√°   N;TRANS;SG   N   TRANS   \n",
       "\n",
       "                                             encoded  \\\n",
       "0  [14, 11, 10, 24, 26, 0, 27, 30, 22, 12, 38, 37...   \n",
       "1  [14, 11, 0, 22, 12, 10, 24, 45, 0, 26, 26, 0, ...   \n",
       "2           [14, 25, 24, 19, 23, 11, 30, 18, 19, 40]   \n",
       "3  [14, 39, 18, 25, 22, 45, 32, 45, 15, 20, 32, 3...   \n",
       "4                       [14, 19, 24, 45, 45, 30, 40]   \n",
       "\n",
       "                                              padded  seqlen  label  \n",
       "0  [14, 11, 10, 24, 26, 0, 27, 30, 22, 12, 38, 37...      16      0  \n",
       "1  [14, 11, 0, 22, 12, 10, 24, 45, 0, 26, 26, 0, ...      14      1  \n",
       "2  [14, 25, 24, 19, 23, 11, 30, 18, 19, 40, 28, 2...      10      2  \n",
       "3  [14, 39, 18, 25, 22, 45, 32, 45, 15, 20, 32, 3...      16      1  \n",
       "4  [14, 19, 24, 45, 45, 30, 40, 28, 28, 28, 28, 2...       7      3  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract input and output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.size() = torch.Size([1000, 29]),\n",
      "y_train.size() = torch.Size([1000])\n",
      "seqlen_train.size() = torch.Size([1000])\n",
      "\n",
      "X_dev.size() = torch.Size([200, 29]),\n",
      "y_dev.size() = torch.Size([200])\n",
      "seqlen_dev.size() = torch.Size([200])\n",
      "\n",
      "X_test.size() = torch.Size([200, 29]),\n",
      "y_test.size() = torch.Size([200])\n",
      "seqlen_test.size() = torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(np.array(list(train_df.padded)))\n",
    "y_train = torch.LongTensor(train_df.label.values) # should convert to Tensor array due to technical reason\n",
    "seqlen_train = torch.LongTensor(train_df.seqlen.values)\n",
    "print(f\"{X_train.size() = },\\n{y_train.size() = }\\n{seqlen_train.size() = }\\n\")\n",
    "\n",
    "X_dev = torch.from_numpy(np.array(list(dev_df.padded)))\n",
    "y_dev = torch.LongTensor(dev_df.label.values)\n",
    "seqlen_dev = torch.LongTensor(dev_df.seqlen.values)\n",
    "print(f\"{X_dev.size() = },\\n{y_dev.size() = }\\n{seqlen_dev.size() = }\\n\")\n",
    "\n",
    "X_test = torch.from_numpy(np.array(list(test_df.padded)))\n",
    "y_test = torch.LongTensor(test_df.label.values)\n",
    "seqlen_test = torch.LongTensor(test_df.seqlen.values)\n",
    "print(f\"{X_test.size() = },\\n{y_test.size() = }\\n{seqlen_test.size() = }\")\n",
    "# result: X_train.size() = torch.Size([1000, 29]), 29 is the length of a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16, 14, 10, 16,  7, 15, 10, 20, 18, 11, 16, 12, 12, 12, 14, 11, 11, 15,\n",
       "        11, 10, 15, 15, 12, 19, 12, 10, 10, 12, 13, 16, 16, 16,  9,  9, 19, 16,\n",
       "        11, 16, 17, 11, 15, 17, 16, 10,  8, 11, 18, 10,  9, 14, 13, 16, 17, 15,\n",
       "        18,  9, 11, 11, 11, 20, 15, 17, 11, 14,  8, 15, 12, 18,  8, 14, 20, 14,\n",
       "        16, 14,  9, 16, 14, 10, 14, 13, 14, 13, 13, 19, 21, 13, 11, 20, 11, 11,\n",
       "        10, 14, 14, 16, 14, 17, 10, 16, 12, 14, 13, 10, 15, 19, 14, 13, 16, 10,\n",
       "        12, 12, 21, 22, 11, 14,  7, 15,  7, 10, 13, 11, 17, 10, 13,  9, 20, 10,\n",
       "        11,  9, 11, 12, 13, 16, 13, 21, 15,  9, 11, 15, 15, 12, 14, 11, 15, 12,\n",
       "        15, 11, 17, 13, 13, 10, 17, 12, 17, 10, 12, 13, 13, 16, 15, 16, 13, 29,\n",
       "        18, 12,  8, 15,  8, 14,  9, 13, 15, 11, 21, 14, 14, 14, 12, 10, 21,  9,\n",
       "        16, 11,  9, 17, 14, 17, 13,  9, 12, 14, 12, 12, 14, 16, 10, 11, 17, 18,\n",
       "        16, 10, 12, 10, 13, 17, 17, 16, 14, 11, 14,  8, 16, 15,  9, 10, 17, 18,\n",
       "        12, 15, 17, 13, 10, 11, 13, 10, 15, 17, 14, 13, 16, 12, 14, 19, 11, 10,\n",
       "        12, 13, 15, 12, 13, 14, 18, 11, 14, 10, 10, 11, 11, 12, 21, 15,  9, 14,\n",
       "        19, 14, 11, 17, 11, 14, 14, 16,  9, 16, 12, 10, 16, 13, 13, 15,  7, 13,\n",
       "        13,  8,  9, 15, 15, 11, 21, 15, 16, 12, 10, 16, 19, 14, 14,  9, 18, 18,\n",
       "        16, 17, 12, 15, 13, 15, 12, 14, 12, 14, 20, 15, 13, 16, 14, 15, 16,  7,\n",
       "        13, 16, 11, 13, 14, 14, 13, 12, 21, 14, 11, 13, 14, 11, 16, 14, 15, 14,\n",
       "        13, 14, 12, 15, 12, 13, 21,  9, 11, 13, 14, 13, 19, 14, 21, 14, 13, 11,\n",
       "         9, 12, 14, 10, 17, 11, 14, 12, 14, 14, 14, 17, 14, 14, 13, 16,  9, 12,\n",
       "        10, 17, 11, 12, 10, 21, 12, 10,  9, 13, 10, 19, 12, 14, 11,  7, 13, 10,\n",
       "        16,  9, 19, 10,  9, 16, 12, 18, 12, 14, 14, 15, 22, 11, 14, 13,  7, 20,\n",
       "        14, 11, 13, 15, 12, 10,  8, 13, 12, 16, 13, 17, 10, 16, 11, 11,  9, 13,\n",
       "         8, 11, 17, 11, 20, 12, 13, 15, 13, 13,  9, 20, 14, 13, 16, 12, 10, 16,\n",
       "        14, 13,  8, 14, 19, 16, 11, 10, 15, 20, 14, 17, 11, 15, 12, 13, 18, 14,\n",
       "        12, 10, 17, 13, 19, 13, 10, 12,  9, 16, 14, 12, 16,  8, 16, 15, 12, 12,\n",
       "        12, 15, 13, 14, 13, 16, 19, 15, 10, 11, 11, 17, 17,  8, 13,  8, 13, 14,\n",
       "        14, 16, 11, 15, 11, 10, 10, 12, 18, 12, 11, 17, 11, 14, 11, 16, 11, 17,\n",
       "        15,  8, 10, 12, 12, 15, 17,  8, 10, 18, 16, 10, 10, 19, 11, 11, 14, 13,\n",
       "        13, 12, 10, 12, 24, 15,  8, 12, 19, 15, 13, 11, 15, 14, 15, 18, 17, 14,\n",
       "        13, 13, 15, 14, 17, 12, 16, 13, 10, 12, 11, 13, 17, 13, 10, 14, 15, 15,\n",
       "        13, 14, 14, 10, 15, 13, 24, 18, 14, 18, 10, 15, 15, 10, 19, 14, 12, 14,\n",
       "        23, 10, 16, 14, 11, 11, 18,  8, 11, 13, 11, 17, 14,  8, 11,  9, 16, 13,\n",
       "        14, 13, 13, 11, 16, 10, 13, 14, 13, 16, 10,  7, 12,  7, 15, 16, 20, 16,\n",
       "         9, 10, 13, 16, 22, 12, 15, 12, 16, 12, 15, 12, 12,  9, 14, 14, 16, 17,\n",
       "        10,  9, 11, 12, 11, 11, 11, 14, 10,  9, 13, 16, 18, 14,  9, 15, 12, 19,\n",
       "        10,  9, 10, 14, 11, 23, 12, 12, 14, 11, 22, 17,  8, 13, 14, 16, 12,  7,\n",
       "        18, 11, 12, 13, 17, 15, 18, 24,  8, 12,  8,  8, 14, 11, 11,  9, 13, 10,\n",
       "        14, 13, 15, 14, 10, 19, 16, 12, 20, 10, 13, 19, 11, 12, 16, 18, 10, 17,\n",
       "        13,  9,  9, 16, 15, 10, 13, 11,  9,  6, 12, 14, 16,  9, 13, 13, 12, 16,\n",
       "        18, 14, 16, 15,  9, 15, 10, 11, 15, 20, 14, 12, 14, 14, 10, 20,  7, 11,\n",
       "        10,  8, 18, 12, 12, 12, 10, 14, 16, 17,  9, 10, 17, 10, 13, 15, 16, 16,\n",
       "        14, 14, 12,  9, 11, 14, 13, 13, 14, 10, 12, 13, 15, 10, 13, 10, 17, 12,\n",
       "        11, 18, 20, 17, 10, 18, 14, 19, 14, 15, 16, 11, 13, 14, 16, 17, 11, 14,\n",
       "         8,  8, 11, 14, 15, 15, 12,  9, 17, 11, 14, 14, 25, 11, 20, 15, 12, 18,\n",
       "        10, 16, 13, 13, 11, 15, 11,  9, 11, 15, 14, 16, 13, 14, 13, 15, 15, 13,\n",
       "        19, 13, 15, 18, 14, 16, 17, 11, 17, 11, 13, 13, 14,  8, 13, 13, 12, 13,\n",
       "        14, 10, 10, 12, 18, 14, 18, 17, 14,  7,  7, 13, 13, 10, 10, 15, 13, 13,\n",
       "        16, 14, 10, 12, 15, 11, 13, 10, 12, 14, 14,  8, 16, 16, 11, 14, 18, 15,\n",
       "        14, 11, 13, 15, 10, 18, 14, 13, 15, 18, 13, 12, 16, 15, 11, 15, 14,  9,\n",
       "        11, 15, 10, 12, 19, 13, 14, 18, 13,  9, 10,  8, 11, 13, 13, 11, 15, 22,\n",
       "        26, 20, 15, 13, 10, 12, 17, 13, 20, 12, 11, 11, 15, 13, 12, 13, 13, 15,\n",
       "        10, 15, 18, 14, 17, 12, 10, 13, 11, 11,  7, 13, 11, 17, 11, 14, 17, 11,\n",
       "        14, 21, 16,  8, 14, 16,  8, 18, 23, 10, 13, 14, 13, 13, 12, 16, 14,  9,\n",
       "         9, 13, 10, 10, 15, 11, 10, 10, 21, 17,  9, 10, 13,  9, 11, 13, 19, 15,\n",
       "        15, 15, 10, 18, 13, 13, 14, 23, 13, 11])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqlen_train # the first value 16 is the original length of the sequence\n",
    "\n",
    "# why need original length? because sometimes we need the actual last element (last character or last word) in the sequence (a word or a sentence) not the PAD.\n",
    "# sometimes, we do not want lstm to process the PAD either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `PackedSequence` (which is used to avoid unecessary processing the PADs in the sequence)\n",
    "\n",
    "We need to modify `LSTMClassifier` to support padding. The last output is now different for each sequence:\n",
    "\n",
    "<img src=\"img/tikz/padding_last_highlight.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dense = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "    # the input signature of forward changes\n",
    "    def forward(self, sequences, sequence_lens):\n",
    "        embedded = self.embedding(sequences)\n",
    "        \n",
    "        # THIS IS THE MODIFIED PART\n",
    "        # returns a PackedSequence object\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded,\n",
    "            sequence_lens, # to specifies the actual end of the sequence, until which lstm should consider\n",
    "            enforce_sorted=False,\n",
    "            batch_first=True)\n",
    "        packed_outputs, (h, c) = self.lstm(packed) # h will not be the last hidden cell but ouput of the actual last hidden cell according to the real sequence length\n",
    "        # extract LSTM outputs (not used here)\n",
    "        lstm_outputs, lens = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
    "        \n",
    "        h = torch.cat((h[0], h[1]), dim=-1)\n",
    "        output = self.dense(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the model\n",
    "\n",
    "The input and the output size are determined by the alphabet and the number of labels, the rest are up to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (embedding): Embedding(46, 30)\n",
       "  (lstm): LSTM(30, 64, batch_first=True, bidirectional=True)\n",
       "  (dense): Linear(in_features=128, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = len(vocab)\n",
    "embedding_size = 30\n",
    "hidden_size = 64\n",
    "output_size = train_df.label.nunique() # number of unique labels\n",
    "\n",
    "model = LSTMClassifier(input_size, embedding_size, hidden_size, output_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching\n",
    "\n",
    "Most datasets do not fit into the GPU memory so we process them in smaller chunks called _batches_.\n",
    "\n",
    "There are many solutions for batching but it can also be implemented with simple class.\n",
    "\n",
    "Note that the init function takes an arbitrary number of positional arguments (`*tensors`) and one mandatory keyword (`batch_size`). This class is a simplified version of batching, it lacks many features such as shuffling or sorting by sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two tensors:\n",
      "([1, 2], [2, 1])\n",
      "([3], [2])\n",
      "\n",
      "One tensor:\n",
      "([2, 1],)\n",
      "([2],)\n"
     ]
    }
   ],
   "source": [
    "class BatchedIterator:\n",
    "    def __init__(self, *tensors, batch_size):\n",
    "        # all tensors must have the same first dimension\n",
    "        assert len(set(len(tensor) for tensor in tensors)) == 1 # make sure every tensor is the same size for batching them together.\n",
    "        self.tensors = tensors\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def iterate_once(self): # to iterate throug the batch size once:\n",
    "        num_data = len(self.tensors[0])\n",
    "        for start in range(0, num_data, self.batch_size):\n",
    "            end = start + self.batch_size\n",
    "            yield tuple(tensor[start:end] for tensor in self.tensors) # when the tuple is finished it goes back to the generator.\n",
    "                                                                      # kind of like an interrrupt.  \n",
    "            \n",
    "            \n",
    "print(\"Two tensors:\")\n",
    "for batch in BatchedIterator([1, 2, 3], [2, 1, 2], batch_size=2).iterate_once():\n",
    "    print(batch)\n",
    "# Two tensors:\n",
    "#([1, 2], [2, 1]) ; [1,2] (2 values because batch_size is 2) are the first two of  [1, 2, 3], [2, 1] are the first two of [2, 1, 2]; \n",
    "#([3], [2]); [3] (the left values are not enough of 2 so it only takes 1) is the last of  [1, 2, 3], [2] are the last of [2, 1, 2]\n",
    "    \n",
    "    \n",
    "print(\"\\nOne tensor:\")\n",
    "for batch in BatchedIterator([2, 1, 2], batch_size=2).iterate_once():\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.size() = torch.Size([501, 29]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([499, 29]), seqlens.size() = torch.Size([499]), y.size() = torch.Size([499])\n"
     ]
    }
   ],
   "source": [
    "train_iter = BatchedIterator(X_train, seqlen_train, y_train, batch_size=501) # if batch size is smaller => more batches; if batch size is too big we could end up with only one batch.\n",
    "for X, seqlens, y in train_iter.iterate_once():\n",
    "    print(f\"{X.size() = }, {seqlens.size() = }, {y.size() = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and optimizer\n",
    "\n",
    "The **loss function** or **cost function** quantifies cost of the model output differing from the expected target values.\n",
    "\n",
    "The optimizer adjusts the model's parameters in accordance with the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # computes the loss to propogate back to each parameters of model\n",
    "optimizer = optim.Adam(model.parameters()) # actually updates the parameters of the model\n",
    "                                           # Adam is a popular one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check (TO MAKE SURE BEFORE TRAINING, THE MODEL SHOULD BE VERY BAD)\n",
    "\n",
    "Train and dev accuracy should be really bad without training.\n",
    "\n",
    "Do **NOT** touch the test data while development finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 8.0%\n"
     ]
    }
   ],
   "source": [
    "logits = model(X_train, seqlen_train)\n",
    "y = logits.argmax(axis=1) # take the highest value of the logits\n",
    "accuracy = torch.sum(torch.eq(y, y_train)) / y.size(0)\n",
    "print(f\"Train accuracy: {accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev accuracy: 11.0%\n"
     ]
    }
   ],
   "source": [
    "logits = model(X_dev, seqlen_dev)\n",
    "y = logits.argmax(axis=1)\n",
    "accuracy = torch.sum(torch.eq(y, y_dev)) / y.size(0)\n",
    "print(f\"Dev accuracy: {accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We collect training statistics at the end of each epochs in `metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "\n",
    "metrics = defaultdict(list)\n",
    "train_iter = BatchedIterator(X_train, seqlen_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model batch by batch and then evaluate it on the train and the dev data at the end of each epoch.\n",
    "Since the dataset is small, we can evaluate it the whole data in one step without batching.\n",
    "\n",
    "Note that the model should be set to **train** or **eval** mode accordingly. Stochastic steps such as dropout are disabled in **eval** mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 -- train_loss=0.018 - train_accuracy=100.0% - dev_loss=0.114 - dev_accuracy=96.5%\n",
      "epoch=1 -- train_loss=0.016 - train_accuracy=100.0% - dev_loss=0.107 - dev_accuracy=97.0%\n",
      "epoch=2 -- train_loss=0.015 - train_accuracy=100.0% - dev_loss=0.117 - dev_accuracy=96.0%\n",
      "epoch=3 -- train_loss=0.013 - train_accuracy=100.0% - dev_loss=0.130 - dev_accuracy=96.0%\n",
      "epoch=4 -- train_loss=0.011 - train_accuracy=100.0% - dev_loss=0.124 - dev_accuracy=96.0%\n",
      "epoch=5 -- train_loss=0.011 - train_accuracy=100.0% - dev_loss=0.116 - dev_accuracy=97.0%\n",
      "epoch=6 -- train_loss=0.009 - train_accuracy=100.0% - dev_loss=0.109 - dev_accuracy=97.0%\n",
      "epoch=7 -- train_loss=0.008 - train_accuracy=100.0% - dev_loss=0.109 - dev_accuracy=97.0%\n",
      "epoch=8 -- train_loss=0.007 - train_accuracy=100.0% - dev_loss=0.112 - dev_accuracy=96.0%\n",
      "epoch=9 -- train_loss=0.007 - train_accuracy=100.0% - dev_loss=0.114 - dev_accuracy=96.0%\n",
      "epoch=10 -- train_loss=0.006 - train_accuracy=100.0% - dev_loss=0.115 - dev_accuracy=96.5%\n",
      "epoch=11 -- train_loss=0.005 - train_accuracy=100.0% - dev_loss=0.117 - dev_accuracy=96.5%\n",
      "epoch=12 -- train_loss=0.005 - train_accuracy=100.0% - dev_loss=0.119 - dev_accuracy=96.5%\n",
      "epoch=13 -- train_loss=0.004 - train_accuracy=100.0% - dev_loss=0.120 - dev_accuracy=97.0%\n",
      "epoch=14 -- train_loss=0.004 - train_accuracy=100.0% - dev_loss=0.119 - dev_accuracy=97.0%\n",
      "epoch=15 -- train_loss=0.004 - train_accuracy=100.0% - dev_loss=0.118 - dev_accuracy=97.0%\n",
      "epoch=16 -- train_loss=0.003 - train_accuracy=100.0% - dev_loss=0.116 - dev_accuracy=97.0%\n",
      "epoch=17 -- train_loss=0.003 - train_accuracy=100.0% - dev_loss=0.117 - dev_accuracy=97.5%\n",
      "epoch=18 -- train_loss=0.003 - train_accuracy=100.0% - dev_loss=0.119 - dev_accuracy=97.5%\n",
      "epoch=19 -- train_loss=0.003 - train_accuracy=100.0% - dev_loss=0.123 - dev_accuracy=97.0%\n",
      "epoch=20 -- train_loss=0.002 - train_accuracy=100.0% - dev_loss=0.126 - dev_accuracy=96.5%\n",
      "epoch=21 -- train_loss=0.002 - train_accuracy=100.0% - dev_loss=0.128 - dev_accuracy=97.0%\n",
      "epoch=22 -- train_loss=0.002 - train_accuracy=100.0% - dev_loss=0.128 - dev_accuracy=97.0%\n",
      "epoch=23 -- train_loss=0.002 - train_accuracy=100.0% - dev_loss=0.127 - dev_accuracy=97.5%\n",
      "epoch=24 -- train_loss=0.002 - train_accuracy=100.0% - dev_loss=0.126 - dev_accuracy=97.5%\n",
      "epoch=25 -- train_loss=0.002 - train_accuracy=100.0% - dev_loss=0.125 - dev_accuracy=97.5%\n",
      "epoch=26 -- train_loss=0.002 - train_accuracy=100.0% - dev_loss=0.124 - dev_accuracy=97.5%\n",
      "epoch=27 -- train_loss=0.002 - train_accuracy=100.0% - dev_loss=0.125 - dev_accuracy=97.5%\n",
      "epoch=28 -- train_loss=0.002 - train_accuracy=100.0% - dev_loss=0.126 - dev_accuracy=97.5%\n",
      "epoch=29 -- train_loss=0.002 - train_accuracy=100.0% - dev_loss=0.127 - dev_accuracy=97.5%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    # Training loop\n",
    "    for X_batch, seqlen_batch, y_batch in train_iter.iterate_once(): # train_iter.iterate_once() to go through a batch at a time\n",
    "        y_out = model(X_batch, seqlen_batch)\n",
    "        loss = criterion(y_out, y_batch) # compute the loss\n",
    "        \n",
    "        # to backpropagate and update the parameters of the model, these commands must be in this order\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()  # or model.train(False)\n",
    "        # Train and dev loss at the end of the epoch\n",
    "        y_out = model(X_train, seqlen_train)\n",
    "        train_loss = criterion(y_out, y_train).item()\n",
    "        metrics['train_loss'].append(train_loss)\n",
    "        labels = y_out.argmax(axis=1)\n",
    "        train_accuracy = (torch.eq(y_train, labels).sum() / labels.size(0)).item()\n",
    "        metrics['train_accuracy'].append(train_accuracy)\n",
    "\n",
    "        \n",
    "        # dev set is used to test the model while training\n",
    "        y_out = model(X_dev, seqlen_dev)\n",
    "        dev_loss = criterion(y_out, y_dev).item()\n",
    "        metrics['dev_loss'].append(dev_loss)\n",
    "        labels = y_out.argmax(axis=1)\n",
    "        dev_accuracy = (torch.eq(y_dev, labels).sum() / labels.size(0)).item()\n",
    "        metrics['dev_accuracy'].append(dev_accuracy)\n",
    "    \n",
    "    print(f\"{epoch=} -- {train_loss=:.3f} - {train_accuracy=:.1%} - {dev_loss=:.3f} - {dev_accuracy=:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "sns.lineplot(data=metrics['train_loss'], ax=ax[0], label='train loss')\n",
    "sns.lineplot(data=metrics['dev_loss'], ax=ax[0], label='dev loss')\n",
    "\n",
    "sns.lineplot(data=metrics['train_accuracy'], ax=ax[1], label='train acc')\n",
    "sns.lineplot(data=metrics['dev_accuracy'], ax=ax[1], label='dev acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 99.0%\n"
     ]
    }
   ],
   "source": [
    "logits = model(X_test, seqlen_test)\n",
    "test_prediction = logits.argmax(axis=1)\n",
    "test_accuracy = torch.sum(torch.eq(test_prediction, y_test)) / y_test.size(0)\n",
    "print(f\"Test accuracy: {test_accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrectly classified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df['prediction'] = test_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovering labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_to_label = {i: l for l, i in label_to_id.items()}\n",
    "test_df['predicted_case'] = test_df['prediction'].apply(lambda id_: id_to_label[id_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infl</th>\n",
       "      <th>case</th>\n",
       "      <th>predicted_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>gyerek√©re</td>\n",
       "      <td>ON+ALL</td>\n",
       "      <td>NOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>s√°m√°n</td>\n",
       "      <td>NOM</td>\n",
       "      <td>ON+ESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          infl    case predicted_case\n",
       "75   gyerek√©re  ON+ALL            NOM\n",
       "177      s√°m√°n     NOM         ON+ESS"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df.prediction != test_df.label][['infl', 'case', 'predicted_case']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further topics\n",
    "\n",
    "## Early stopping\n",
    "\n",
    "Stop the training process if the development metrics no longer improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "Dropout disables a random subset of neurons during each training step. It's generally set to 10-20%. Dropout usually improves generalization.\n",
    "\n",
    "It should be disabled in evaluation steps and during inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Fit the train set very closely but lose generalization.\n",
    "\n",
    "[Image source](https://www.quora.com/What-are-the-key-trade-offs-between-overfitting-and-underfitting)\n",
    "\n",
    "<img src=\"img/dl/overfitting.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the GPU\n",
    "\n",
    "Moving things manually to the GPU:\n",
    "- model: move once\n",
    "- criterion: move once\n",
    "- data: move one batch at a time\n",
    "\n",
    "This should be automatically handled by your code the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading models\n",
    "\n",
    "All `nn.Modules` have a `state_dict` attribute, a dictionary of their parameters. This can be partially or fully saved with `torch.save` and loaded by `torch.load`.\n",
    "\n",
    "[Official tutorial](https://pytorch.org/tutorials/beginner/saving_loading_models.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "**Inference** is when we use the model for prediction and do not train it.\n",
    "\n",
    "The models should be set to `eval` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
